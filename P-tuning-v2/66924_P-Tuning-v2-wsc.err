
CondaSystemExit: Exiting.



==> WARNING: A newer version of conda exists. <==
  current version: 4.11.0
  latest version: 4.12.0

Please update conda by running

    $ conda update -n base -c defaults conda


Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|tokenization_auto.py:334] 2022-04-17 21:25:34,316 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:583] 2022-04-17 21:25:34,447 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:34,448 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /home/ask9126/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /home/ask9126/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /home/ask9126/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-04-17 21:25:35,389 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None
[INFO|configuration_utils.py:583] 2022-04-17 21:25:35,514 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:35,515 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

Downloading:   0%|          | 0.00/32.8k [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.8k/32.8k [00:00<00:00, 465kB/s]
0 examples [00:00, ? examples/s]                                0 examples [00:00, ? examples/s]                                0 examples [00:00, ? examples/s]                                  0%|          | 0/3 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 165.45it/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 15.02ba/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 69.96ba/s]
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 61.92ba/s]
[INFO|configuration_utils.py:583] 2022-04-17 21:25:38,565 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /home/ask9126/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-04-17 21:25:38,565 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "finetuning_task": "wsc",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "id2label": {
    "0": "False",
    "1": "True"
  },
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "label2id": {
    "False": 0,
    "True": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:1323] 2022-04-17 21:25:38,697 >> loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /home/ask9126/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352
[WARNING|modeling_utils.py:1579] 2022-04-17 21:25:51,934 >> Some weights of the model checkpoint at roberta-large were not used when initializing RobertaPrefixForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaPrefixForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1590] 2022-04-17 21:25:51,934 >> Some weights of RobertaPrefixForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.embeddings.position_ids', 'prefix_encoder.embedding.weight', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|trainer.py:540] 2022-04-17 21:26:01,487 >> The following columns in the training set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:1196] 2022-04-17 21:26:01,514 >> ***** Running training *****
[INFO|trainer.py:1197] 2022-04-17 21:26:01,514 >>   Num examples = 554
[INFO|trainer.py:1198] 2022-04-17 21:26:01,514 >>   Num Epochs = 10
[INFO|trainer.py:1199] 2022-04-17 21:26:01,514 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1200] 2022-04-17 21:26:01,514 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1201] 2022-04-17 21:26:01,514 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2022-04-17 21:26:01,514 >>   Total optimization steps = 350
  0%|          | 0/350 [00:00<?, ?it/s]  0%|          | 1/350 [00:02<14:13,  2.45s/it]  1%|          | 2/350 [00:02<06:42,  1.16s/it]  1%|          | 3/350 [00:02<04:18,  1.34it/s]  1%|          | 4/350 [00:03<03:10,  1.82it/s]  1%|â–         | 5/350 [00:03<02:32,  2.26it/s]  2%|â–         | 6/350 [00:03<02:10,  2.64it/s]  2%|â–         | 7/350 [00:03<01:55,  2.97it/s]  2%|â–         | 8/350 [00:04<01:46,  3.22it/s]  3%|â–Ž         | 9/350 [00:04<01:39,  3.42it/s]  3%|â–Ž         | 10/350 [00:04<01:35,  3.57it/s]  3%|â–Ž         | 11/350 [00:04<01:32,  3.68it/s]  3%|â–Ž         | 12/350 [00:05<01:29,  3.76it/s]  4%|â–Ž         | 13/350 [00:05<01:28,  3.82it/s]  4%|â–         | 14/350 [00:05<01:27,  3.85it/s]  4%|â–         | 15/350 [00:05<01:26,  3.88it/s]  5%|â–         | 16/350 [00:06<01:25,  3.89it/s]  5%|â–         | 17/350 [00:06<01:25,  3.91it/s]  5%|â–Œ         | 18/350 [00:06<01:24,  3.91it/s]  5%|â–Œ         | 19/350 [00:07<01:24,  3.92it/s]  6%|â–Œ         | 20/350 [00:07<01:24,  3.92it/s]  6%|â–Œ         | 21/350 [00:07<01:23,  3.93it/s]  6%|â–‹         | 22/350 [00:07<01:23,  3.92it/s]  7%|â–‹         | 23/350 [00:08<01:23,  3.93it/s]  7%|â–‹         | 24/350 [00:08<01:22,  3.94it/s]  7%|â–‹         | 25/350 [00:08<01:22,  3.94it/s]  7%|â–‹         | 26/350 [00:08<01:22,  3.94it/s]  8%|â–Š         | 27/350 [00:09<01:22,  3.93it/s]  8%|â–Š         | 28/350 [00:09<01:21,  3.93it/s]  8%|â–Š         | 29/350 [00:09<01:21,  3.93it/s]  9%|â–Š         | 30/350 [00:09<01:21,  3.93it/s]  9%|â–‰         | 31/350 [00:10<01:21,  3.93it/s]  9%|â–‰         | 32/350 [00:10<01:20,  3.93it/s]  9%|â–‰         | 33/350 [00:10<01:20,  3.93it/s] 10%|â–‰         | 34/350 [00:10<01:20,  3.93it/s] 10%|â–ˆ         | 35/350 [00:10<01:10,  4.46it/s][INFO|trainer.py:540] 2022-04-17 21:26:12,492 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:12,494 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:12,494 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:12,494 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 23.08it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.81it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.83it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.31it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.95it/s][A                                                
                                               [A 10%|â–ˆ         | 35/350 [00:11<01:10,  4.46it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.95it/s][A
                                               [A                                                 10%|â–ˆ         | 35/350 [00:11<01:10,  4.46it/s] 10%|â–ˆ         | 36/350 [00:12<02:37,  1.99it/s] 11%|â–ˆ         | 37/350 [00:12<02:14,  2.33it/s] 11%|â–ˆ         | 38/350 [00:12<01:57,  2.66it/s] 11%|â–ˆ         | 39/350 [00:12<01:45,  2.94it/s] 11%|â–ˆâ–        | 40/350 [00:13<01:37,  3.18it/s] 12%|â–ˆâ–        | 41/350 [00:13<01:31,  3.38it/s] 12%|â–ˆâ–        | 42/350 [00:13<01:27,  3.53it/s] 12%|â–ˆâ–        | 43/350 [00:13<01:24,  3.64it/s] 13%|â–ˆâ–Ž        | 44/350 [00:14<01:21,  3.74it/s] 13%|â–ˆâ–Ž        | 45/350 [00:14<01:20,  3.79it/s] 13%|â–ˆâ–Ž        | 46/350 [00:14<01:19,  3.83it/s] 13%|â–ˆâ–Ž        | 47/350 [00:14<01:18,  3.87it/s] 14%|â–ˆâ–Ž        | 48/350 [00:15<01:17,  3.89it/s] 14%|â–ˆâ–        | 49/350 [00:15<01:17,  3.91it/s] 14%|â–ˆâ–        | 50/350 [00:15<01:16,  3.92it/s] 15%|â–ˆâ–        | 51/350 [00:15<01:16,  3.93it/s] 15%|â–ˆâ–        | 52/350 [00:16<01:15,  3.93it/s] 15%|â–ˆâ–Œ        | 53/350 [00:16<01:15,  3.92it/s] 15%|â–ˆâ–Œ        | 54/350 [00:16<01:15,  3.92it/s] 16%|â–ˆâ–Œ        | 55/350 [00:16<01:15,  3.92it/s] 16%|â–ˆâ–Œ        | 56/350 [00:17<01:14,  3.93it/s] 16%|â–ˆâ–‹        | 57/350 [00:17<01:14,  3.93it/s] 17%|â–ˆâ–‹        | 58/350 [00:17<01:14,  3.94it/s] 17%|â–ˆâ–‹        | 59/350 [00:17<01:13,  3.95it/s] 17%|â–ˆâ–‹        | 60/350 [00:18<01:13,  3.94it/s] 17%|â–ˆâ–‹        | 61/350 [00:18<01:13,  3.93it/s] 18%|â–ˆâ–Š        | 62/350 [00:18<01:13,  3.93it/s] 18%|â–ˆâ–Š        | 63/350 [00:18<01:13,  3.92it/s] 18%|â–ˆâ–Š        | 64/350 [00:19<01:12,  3.92it/s] 19%|â–ˆâ–Š        | 65/350 [00:19<01:12,  3.92it/s] 19%|â–ˆâ–‰        | 66/350 [00:19<01:12,  3.93it/s] 19%|â–ˆâ–‰        | 67/350 [00:20<01:12,  3.93it/s] 19%|â–ˆâ–‰        | 68/350 [00:20<01:11,  3.93it/s] 20%|â–ˆâ–‰        | 69/350 [00:20<01:11,  3.91it/s] 20%|â–ˆâ–ˆ        | 70/350 [00:20<01:02,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:22,190 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:22,192 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:22,192 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:22,192 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 23.08it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.74it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.76it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.21it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.91it/s][A                                                
                                               [A 20%|â–ˆâ–ˆ        | 70/350 [00:21<01:02,  4.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.91it/s][A
                                               [A                                                 20%|â–ˆâ–ˆ        | 70/350 [00:21<01:02,  4.45it/s] 20%|â–ˆâ–ˆ        | 71/350 [00:21<02:18,  2.01it/s] 21%|â–ˆâ–ˆ        | 72/350 [00:22<01:58,  2.36it/s] 21%|â–ˆâ–ˆ        | 73/350 [00:22<01:43,  2.68it/s] 21%|â–ˆâ–ˆ        | 74/350 [00:22<01:33,  2.96it/s] 21%|â–ˆâ–ˆâ–       | 75/350 [00:22<01:26,  3.19it/s] 22%|â–ˆâ–ˆâ–       | 76/350 [00:23<01:21,  3.37it/s] 22%|â–ˆâ–ˆâ–       | 77/350 [00:23<01:17,  3.51it/s] 22%|â–ˆâ–ˆâ–       | 78/350 [00:23<01:14,  3.63it/s] 23%|â–ˆâ–ˆâ–Ž       | 79/350 [00:23<01:13,  3.71it/s] 23%|â–ˆâ–ˆâ–Ž       | 80/350 [00:24<01:11,  3.77it/s] 23%|â–ˆâ–ˆâ–Ž       | 81/350 [00:24<01:10,  3.81it/s] 23%|â–ˆâ–ˆâ–Ž       | 82/350 [00:24<01:09,  3.84it/s] 24%|â–ˆâ–ˆâ–Ž       | 83/350 [00:24<01:09,  3.87it/s] 24%|â–ˆâ–ˆâ–       | 84/350 [00:25<01:08,  3.88it/s] 24%|â–ˆâ–ˆâ–       | 85/350 [00:25<01:08,  3.89it/s] 25%|â–ˆâ–ˆâ–       | 86/350 [00:25<01:07,  3.91it/s] 25%|â–ˆâ–ˆâ–       | 87/350 [00:25<01:07,  3.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 88/350 [00:26<01:07,  3.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 89/350 [00:26<01:06,  3.91it/s] 26%|â–ˆâ–ˆâ–Œ       | 90/350 [00:26<01:06,  3.91it/s] 26%|â–ˆâ–ˆâ–Œ       | 91/350 [00:26<01:06,  3.92it/s] 26%|â–ˆâ–ˆâ–‹       | 92/350 [00:27<01:05,  3.92it/s] 27%|â–ˆâ–ˆâ–‹       | 93/350 [00:27<01:05,  3.93it/s] 27%|â–ˆâ–ˆâ–‹       | 94/350 [00:27<01:05,  3.92it/s] 27%|â–ˆâ–ˆâ–‹       | 95/350 [00:27<01:04,  3.93it/s] 27%|â–ˆâ–ˆâ–‹       | 96/350 [00:28<01:04,  3.93it/s] 28%|â–ˆâ–ˆâ–Š       | 97/350 [00:28<01:04,  3.94it/s] 28%|â–ˆâ–ˆâ–Š       | 98/350 [00:28<01:04,  3.93it/s] 28%|â–ˆâ–ˆâ–Š       | 99/350 [00:28<01:03,  3.93it/s] 29%|â–ˆâ–ˆâ–Š       | 100/350 [00:29<01:03,  3.93it/s] 29%|â–ˆâ–ˆâ–‰       | 101/350 [00:29<01:03,  3.93it/s] 29%|â–ˆâ–ˆâ–‰       | 102/350 [00:29<01:02,  3.94it/s] 29%|â–ˆâ–ˆâ–‰       | 103/350 [00:29<01:02,  3.93it/s] 30%|â–ˆâ–ˆâ–‰       | 104/350 [00:30<01:02,  3.93it/s] 30%|â–ˆâ–ˆâ–ˆ       | 105/350 [00:30<00:54,  4.46it/s][INFO|trainer.py:540] 2022-04-17 21:26:31,890 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:31,892 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:31,892 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:31,892 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.96it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.72it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.71it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.19it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.88it/s][A                                                 
                                               [A 30%|â–ˆâ–ˆâ–ˆ       | 105/350 [00:31<00:54,  4.46it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.88it/s][A
                                               [A                                                  30%|â–ˆâ–ˆâ–ˆ       | 105/350 [00:31<00:54,  4.46it/s] 30%|â–ˆâ–ˆâ–ˆ       | 106/350 [00:31<02:01,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆ       | 107/350 [00:31<01:43,  2.35it/s] 31%|â–ˆâ–ˆâ–ˆ       | 108/350 [00:32<01:30,  2.67it/s] 31%|â–ˆâ–ˆâ–ˆ       | 109/350 [00:32<01:21,  2.95it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 110/350 [00:32<01:15,  3.18it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 111/350 [00:32<01:10,  3.37it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 112/350 [00:33<01:07,  3.52it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/350 [00:33<01:05,  3.63it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 114/350 [00:33<01:03,  3.71it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 115/350 [00:33<01:02,  3.78it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 116/350 [00:34<01:01,  3.82it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/350 [00:34<01:00,  3.86it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/350 [00:34<00:59,  3.88it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 119/350 [00:34<00:59,  3.90it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 120/350 [00:35<00:58,  3.90it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 121/350 [00:35<00:58,  3.91it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 122/350 [00:35<00:58,  3.90it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 123/350 [00:35<00:57,  3.92it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 124/350 [00:36<00:57,  3.92it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/350 [00:36<00:57,  3.92it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/350 [00:36<00:57,  3.93it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 127/350 [00:36<00:56,  3.93it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 128/350 [00:37<00:56,  3.93it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 129/350 [00:37<00:56,  3.93it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 130/350 [00:37<00:56,  3.93it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/350 [00:37<00:55,  3.92it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 132/350 [00:38<00:55,  3.92it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 133/350 [00:38<00:55,  3.92it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/350 [00:38<00:55,  3.92it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 135/350 [00:38<00:54,  3.92it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 136/350 [00:39<00:54,  3.92it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 137/350 [00:39<00:54,  3.91it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 138/350 [00:39<00:54,  3.91it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 139/350 [00:39<00:53,  3.91it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 140/350 [00:40<00:47,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:41,598 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:41,600 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:41,600 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:41,600 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 23.13it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.78it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.74it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.21it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.87it/s][A                                                 
                                               [A 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 140/350 [00:40<00:47,  4.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.87it/s][A
                                               [A                                                  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 140/350 [00:40<00:47,  4.45it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 141/350 [00:41<01:45,  1.99it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 142/350 [00:41<01:29,  2.33it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/350 [00:41<01:18,  2.65it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/350 [00:41<01:10,  2.94it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 145/350 [00:42<01:04,  3.17it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 146/350 [00:42<01:00,  3.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147/350 [00:42<00:57,  3.52it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/350 [00:43<00:55,  3.63it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 149/350 [00:43<00:54,  3.71it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 150/350 [00:43<00:52,  3.78it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 151/350 [00:43<00:52,  3.82it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152/350 [00:44<00:51,  3.85it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/350 [00:44<00:50,  3.87it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 154/350 [00:44<00:50,  3.88it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 155/350 [00:44<00:50,  3.88it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 156/350 [00:45<00:49,  3.89it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/350 [00:45<00:49,  3.90it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 158/350 [00:45<00:49,  3.91it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 159/350 [00:45<00:48,  3.91it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 160/350 [00:46<00:48,  3.91it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/350 [00:46<00:48,  3.91it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 162/350 [00:46<00:48,  3.91it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 163/350 [00:46<00:47,  3.91it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 164/350 [00:47<00:47,  3.92it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 165/350 [00:47<00:47,  3.91it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 166/350 [00:47<00:47,  3.91it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 167/350 [00:47<00:46,  3.91it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 168/350 [00:48<00:46,  3.91it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 169/350 [00:48<00:46,  3.92it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/350 [00:48<00:45,  3.93it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 171/350 [00:48<00:45,  3.93it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 172/350 [00:49<00:45,  3.92it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 173/350 [00:49<00:45,  3.92it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 174/350 [00:49<00:44,  3.92it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 175/350 [00:49<00:39,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:26:51,330 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:26:51,332 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:26:51,332 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:26:51,332 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.90it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.57it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.63it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.08it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.75it/s][A                                                 
                                               [A 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 175/350 [00:50<00:39,  4.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.75it/s][A
                                               [A                                                  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 175/350 [00:50<00:39,  4.45it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 176/350 [00:50<01:27,  1.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 177/350 [00:51<01:14,  2.34it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 178/350 [00:51<01:04,  2.66it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/350 [00:51<00:58,  2.93it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 180/350 [00:51<00:53,  3.17it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 181/350 [00:52<00:50,  3.37it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 182/350 [00:52<00:47,  3.51it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/350 [00:52<00:46,  3.62it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 184/350 [00:53<00:44,  3.70it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 185/350 [00:53<00:43,  3.77it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 186/350 [00:53<00:42,  3.81it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 187/350 [00:53<00:42,  3.85it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 188/350 [00:54<00:41,  3.87it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 189/350 [00:54<00:41,  3.88it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 190/350 [00:54<00:41,  3.89it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 191/350 [00:54<00:40,  3.90it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 192/350 [00:55<00:40,  3.90it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 193/350 [00:55<00:40,  3.90it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 194/350 [00:55<00:40,  3.90it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 195/350 [00:55<00:39,  3.89it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 196/350 [00:56<00:39,  3.90it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 197/350 [00:56<00:39,  3.90it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 198/350 [00:56<00:38,  3.91it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 199/350 [00:56<00:38,  3.91it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 200/350 [00:57<00:38,  3.91it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/350 [00:57<00:38,  3.90it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 202/350 [00:57<00:37,  3.91it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 203/350 [00:57<00:37,  3.90it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 204/350 [00:58<00:37,  3.91it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 205/350 [00:58<00:37,  3.91it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 206/350 [00:58<00:36,  3.91it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 207/350 [00:58<00:36,  3.90it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 208/350 [00:59<00:36,  3.90it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 209/350 [00:59<00:36,  3.90it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210/350 [00:59<00:31,  4.43it/s][INFO|trainer.py:540] 2022-04-17 21:27:01,077 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:01,079 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:01,079 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:01,079 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.99it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.66it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.66it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.82it/s][A                                                 
                                               [A 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210/350 [01:00<00:31,  4.43it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.82it/s][A
                                               [A                                                  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 210/350 [01:00<00:31,  4.43it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 211/350 [01:00<01:09,  1.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 212/350 [01:00<00:59,  2.33it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 213/350 [01:01<00:51,  2.65it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 214/350 [01:01<00:46,  2.94it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 215/350 [01:01<00:42,  3.17it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 216/350 [01:01<00:39,  3.37it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 217/350 [01:02<00:37,  3.51it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 218/350 [01:02<00:36,  3.61it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 219/350 [01:02<00:35,  3.69it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 220/350 [01:03<00:34,  3.76it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 221/350 [01:03<00:33,  3.81it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 222/350 [01:03<00:33,  3.83it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 223/350 [01:03<00:32,  3.86it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 224/350 [01:04<00:32,  3.89it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 225/350 [01:04<00:32,  3.89it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 226/350 [01:04<00:31,  3.90it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 227/350 [01:04<00:31,  3.90it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 228/350 [01:05<00:31,  3.91it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 229/350 [01:05<00:31,  3.90it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 230/350 [01:05<00:30,  3.91it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 231/350 [01:05<00:30,  3.91it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 232/350 [01:06<00:30,  3.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 233/350 [01:06<00:29,  3.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 234/350 [01:06<00:29,  3.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 235/350 [01:06<00:29,  3.91it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 236/350 [01:07<00:29,  3.92it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 237/350 [01:07<00:28,  3.91it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 238/350 [01:07<00:28,  3.91it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 239/350 [01:07<00:28,  3.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 240/350 [01:08<00:28,  3.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 241/350 [01:08<00:27,  3.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 242/350 [01:08<00:27,  3.92it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 243/350 [01:08<00:27,  3.93it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 244/350 [01:09<00:27,  3.92it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 245/350 [01:09<00:23,  4.45it/s][INFO|trainer.py:540] 2022-04-17 21:27:10,813 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:10,815 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:10,815 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:10,815 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.99it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.64it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.72it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.75it/s][A                                                 
                                               [A 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 245/350 [01:10<00:23,  4.45it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.75it/s][A
                                               [A                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 245/350 [01:10<00:23,  4.45it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 246/350 [01:10<00:52,  2.00it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 247/350 [01:10<00:43,  2.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 248/350 [01:10<00:38,  2.66it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 249/350 [01:11<00:34,  2.94it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 250/350 [01:11<00:31,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 251/350 [01:11<00:29,  3.37it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 252/350 [01:11<00:27,  3.51it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 253/350 [01:12<00:26,  3.63it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 254/350 [01:12<00:25,  3.70it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 255/350 [01:12<00:25,  3.77it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 256/350 [01:12<00:24,  3.81it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 257/350 [01:13<00:24,  3.84it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 258/350 [01:13<00:23,  3.86it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 259/350 [01:13<00:23,  3.88it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 260/350 [01:14<00:23,  3.88it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 261/350 [01:14<00:22,  3.89it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 262/350 [01:14<00:22,  3.90it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 263/350 [01:14<00:22,  3.91it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 264/350 [01:15<00:22,  3.90it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 265/350 [01:15<00:21,  3.90it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 266/350 [01:15<00:21,  3.89it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 267/350 [01:15<00:21,  3.90it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 268/350 [01:16<00:21,  3.90it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 269/350 [01:16<00:20,  3.90it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 270/350 [01:16<00:20,  3.91it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 271/350 [01:16<00:20,  3.90it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 272/350 [01:17<00:19,  3.91it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 273/350 [01:17<00:19,  3.92it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 274/350 [01:17<00:19,  3.92it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 275/350 [01:17<00:19,  3.92it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 276/350 [01:18<00:18,  3.93it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 277/350 [01:18<00:18,  3.92it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 278/350 [01:18<00:18,  3.93it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 279/350 [01:18<00:18,  3.92it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 280/350 [01:19<00:15,  4.44it/s][INFO|trainer.py:540] 2022-04-17 21:27:20,547 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:20,549 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:20,549 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:20,549 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.68it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.52it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.59it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.11it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.80it/s][A                                                 
                                               [A 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 280/350 [01:19<00:15,  4.44it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.80it/s][A
                                               [A                                                  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 280/350 [01:19<00:15,  4.44it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 281/350 [01:20<00:34,  1.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 282/350 [01:20<00:29,  2.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 283/350 [01:20<00:25,  2.65it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 284/350 [01:20<00:22,  2.94it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 285/350 [01:21<00:20,  3.17it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 286/350 [01:21<00:19,  3.36it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 287/350 [01:21<00:17,  3.51it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 288/350 [01:21<00:17,  3.62it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 289/350 [01:22<00:16,  3.70it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 290/350 [01:22<00:15,  3.77it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 291/350 [01:22<00:15,  3.81it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 292/350 [01:23<00:15,  3.80it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 293/350 [01:23<00:14,  3.83it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/350 [01:23<00:14,  3.86it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 295/350 [01:23<00:14,  3.87it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 296/350 [01:24<00:13,  3.88it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 297/350 [01:24<00:13,  3.89it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 298/350 [01:24<00:13,  3.90it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 299/350 [01:24<00:13,  3.91it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 300/350 [01:25<00:12,  3.90it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 301/350 [01:25<00:12,  3.90it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 302/350 [01:25<00:12,  3.90it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 303/350 [01:25<00:12,  3.91it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 304/350 [01:26<00:11,  3.90it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 305/350 [01:26<00:11,  3.91it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 306/350 [01:26<00:11,  3.91it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 307/350 [01:26<00:10,  3.91it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 308/350 [01:27<00:10,  3.91it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 309/350 [01:27<00:10,  3.92it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 310/350 [01:27<00:10,  3.91it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 311/350 [01:27<00:09,  3.91it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 312/350 [01:28<00:09,  3.91it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 313/350 [01:28<00:09,  3.90it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 314/350 [01:28<00:09,  3.90it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 315/350 [01:28<00:07,  4.43it/s][INFO|trainer.py:540] 2022-04-17 21:27:30,304 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:30,306 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:30,306 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:30,306 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 22.77it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.59it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.65it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.12it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.83it/s][A                                                 
                                               [A 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 315/350 [01:29<00:07,  4.43it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.83it/s][A
                                               [A                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 315/350 [01:29<00:07,  4.43it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 316/350 [01:29<00:17,  2.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 317/350 [01:30<00:14,  2.33it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 318/350 [01:30<00:12,  2.66it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 319/350 [01:30<00:10,  2.94it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 320/350 [01:30<00:09,  3.18it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 321/350 [01:31<00:08,  3.37it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 322/350 [01:31<00:07,  3.51it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 323/350 [01:31<00:07,  3.62it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 324/350 [01:31<00:07,  3.70it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 325/350 [01:32<00:06,  3.77it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 326/350 [01:32<00:06,  3.81it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 327/350 [01:32<00:05,  3.84it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 328/350 [01:32<00:05,  3.86it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/350 [01:33<00:05,  3.87it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/350 [01:33<00:05,  3.88it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 331/350 [01:33<00:04,  3.89it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 332/350 [01:34<00:04,  3.90it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 333/350 [01:34<00:04,  3.90it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 334/350 [01:34<00:04,  3.90it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 335/350 [01:34<00:03,  3.90it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 336/350 [01:35<00:03,  3.91it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 337/350 [01:35<00:03,  3.91it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 338/350 [01:35<00:03,  3.91it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 339/350 [01:35<00:02,  3.90it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 340/350 [01:36<00:02,  3.90it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 341/350 [01:36<00:02,  3.90it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 342/350 [01:36<00:02,  3.90it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 343/350 [01:36<00:01,  3.90it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 344/350 [01:37<00:01,  3.89it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 345/350 [01:37<00:01,  3.89it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 346/350 [01:37<00:01,  3.90it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 347/350 [01:37<00:00,  3.91it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 348/350 [01:38<00:00,  3.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 349/350 [01:38<00:00,  3.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [01:38<00:00,  4.42it/s][INFO|trainer.py:540] 2022-04-17 21:27:40,055 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForSequenceClassification.forward` and have been ignored: idx, span2_text, text, span1_index, span2_index, span1_text, span2_word_text.
[INFO|trainer.py:2243] 2022-04-17 21:27:40,057 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-04-17 21:27:40,057 >>   Num examples = 104
[INFO|trainer.py:2248] 2022-04-17 21:27:40,057 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 3/13 [00:00<00:00, 23.00it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 6/13 [00:00<00:00, 17.62it/s][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 8/13 [00:00<00:00, 16.70it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 10/13 [00:00<00:00, 16.13it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 12/13 [00:00<00:00, 15.77it/s][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [01:39<00:00,  4.42it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 15.77it/s][A
                                               [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [01:39<00:00,  4.42it/s][INFO|trainer.py:1409] 2022-04-17 21:27:40,946 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [01:39<00:00,  4.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [01:39<00:00,  3.52it/s]
